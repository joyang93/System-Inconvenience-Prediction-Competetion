{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 데이콘 BASELINE 코드 기본틀 토대로 수정하여 작성하였습니다.  \n",
    "(https://dacon.io/competitions/official/235687/codeshare/2108?page=1&dtype=recent&ptype=pub)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtmSby3NERyi"
   },
   "source": [
    "# 1. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 7042,
     "status": "ok",
     "timestamp": 1612436786975,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "Jjhblm8gERyj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "RAW_PATH = '../data/raw/'\n",
    "PATH = '../data/final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 불러오기 & 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9863,
     "status": "ok",
     "timestamp": 1612437848426,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "uh4tXPFKTW01",
    "outputId": "24f35899-9b55-417c-df02-409739e8ea50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 1322)\n",
      "(15000, 1840)\n",
      "(15000, 1893)\n",
      "(15000, 1894)\n",
      "(15000, 3448)\n",
      "(15000, 3449)\n",
      "(15000, 3613)\n",
      "(15000, 3631)\n",
      "(15000, 3994)\n",
      "(15000, 4005)\n",
      "(15000, 4011)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.load(PATH + \"train_df_err_cnt.npy\")\n",
    "test_x = np.load(PATH + \"test_df_err_cnt.npy\")\n",
    "\n",
    "train_x_reg = pd.read_pickle(PATH  + \"train_typecode_reg.pkl\")\n",
    "train_x_reg = np.reshape(train_x_reg.iloc[:,2:].values, [15000,-1])\n",
    "test_x_reg = pd.read_pickle(PATH  + \"test_typecode_reg.pkl\")\n",
    "test_x_reg = np.reshape(test_x_reg.iloc[:,2:].values, [14999,-1])\n",
    "\n",
    "train_x_ratio = np.load(PATH + \"train_ratio_unique_cnt_features.npy\")\n",
    "test_x_ratio = np.load(PATH + \"test_ratio_unique_cnt_features.npy\")\n",
    "train_eq_tp_cd_prob = np.reshape(pd.read_pickle(PATH + \"train_eq_tp_cd_prob.pkl\").iloc[:,1].values, [15000,-1])\n",
    "\n",
    "source_df = pd.DataFrame({\"user_id\" : [i for i in range(30000, 44999)]})\n",
    "test_eq_tp_cd_prob = pd.merge(source_df, pd.read_pickle(PATH + \"test_eq_tp_cd_prob.pkl\"), on =\"user_id\", how ='left').fillna(0)\n",
    "\n",
    "test_eq_tp_cd_prob = np.reshape(test_eq_tp_cd_prob.iloc[:,1].values, [14999,-1])\n",
    "test_ty_cd_timestamp = pd.read_pickle(PATH + \"test_ty_cd_timestamp_feature.pkl\")\n",
    "train_ty_cd_timestamp = pd.read_pickle(PATH + \"train_ty_cd_timestamp_feature.pkl\")\n",
    "train_ty_cd_timestamp = np.reshape(train_ty_cd_timestamp.iloc[:,2:].values,[15000, -1])\n",
    "test_ty_cd_timestamp = np.reshape(test_ty_cd_timestamp.iloc[:,2:].values,[14999, -1])\n",
    "\n",
    "\n",
    "train_simul_prob_top_cnt = np.reshape(pd.read_pickle(PATH + \"train_simul_prob_top_cnt.pkl\").iloc[:,1].values, [15000, -1])\n",
    "test_simul_prob_top_cnt = np.reshape(pd.read_pickle(PATH + \"test_simul_prob_top_cnt.pkl\").iloc[:,1].values, [14999,-1])\n",
    "\n",
    "train_timedelta_static = np.load(PATH + \"train_timedelta_static.npy\")\n",
    "test_timedelta_static = np.load(PATH + \"test_timedelta_static_.npy\")\n",
    "\n",
    "\n",
    "fpca_results = pd.read_csv(PATH + \"fpca_result_hours_rv.tsv\", sep = '\\t',  index_col=None)\n",
    "train_fpca = fpca_results.iloc[:15000, 1:].values\n",
    "test_fpca = fpca_results.iloc[15000:, 1:].values\n",
    "train_quality_timestamp_features = pd.read_pickle(PATH + \"train_quality_timestamp_features.pkl\")\n",
    "test_quality_timestamp_features = pd.read_pickle(PATH + \"test_quality_timestamp_features.pkl\")\n",
    "\n",
    "use_cols =[\"count/time_min_max_intervalquality_\"+str(i) for i in range(0,13)]\n",
    "use_cols.remove('count/time_min_max_intervalquality_4')\n",
    "use_cols.remove('count/time_min_max_intervalquality_3')\n",
    "\n",
    "train_quality_timestamp_features = train_quality_timestamp_features[use_cols]\n",
    "train_quality_timestamp_features = np.reshape(train_quality_timestamp_features.values, [15000, -1])\n",
    "\n",
    "test_quality_timestamp_features = test_quality_timestamp_features[use_cols]\n",
    "test_quality_timestamp_features =  np.reshape(test_quality_timestamp_features.values, [14999, -1])\n",
    "train_quality_negaive_value_cnt = pd.read_pickle(PATH + \"train_quality_negaive_value_cnt.pkl\").fillna(0).iloc[:,1:].values\n",
    "test_quality_negaive_value_cnt = pd.read_pickle(PATH + \"test_quality_negaive_value_cnt.pkl\").fillna(0).iloc[:,1:].values\n",
    "train_simultaneous_quality_features = pd.read_pickle(PATH + \"train_simultaneous_quality_features.pkl\")\n",
    "train_simultaneous_quality_features[\"ratio\"] = train_simultaneous_quality_features[\"simul_cnt_max\"]/train_simultaneous_quality_features[\"simul_cnt_mean\"]\n",
    "test_simultaneous_quality_features = pd.read_pickle(PATH + \"test_simultaneous_quality_features.pkl\")\n",
    "test_simultaneous_quality_features[\"ratio\"] = test_simultaneous_quality_features[\"simul_cnt_max\"]/test_simultaneous_quality_features[\"simul_cnt_mean\"]\n",
    "train_simultaneous_quality_features = train_simultaneous_quality_features.fillna(0)\n",
    "test_simultaneous_quality_features = test_simultaneous_quality_features.fillna(0)\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_x_reg, axis =1)\n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_x_ratio, axis =1)\n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_eq_tp_cd_prob, axis =1)\n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_ty_cd_timestamp, axis =1) \n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_simul_prob_top_cnt, axis =1)\n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_timedelta_static, axis =1)\n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_fpca, axis =1)\n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_quality_timestamp_features, axis =1)\n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_quality_negaive_value_cnt, axis =1)\n",
    "print(train_x.shape)\n",
    "train_x = np.append(train_x, train_simultaneous_quality_features.iloc[:,1:].values, axis =1)\n",
    "print(train_x.shape)\n",
    "\n",
    "\n",
    "test_x = np.append(test_x, test_x_reg, axis = 1)\n",
    "test_x = np.append(test_x, test_x_ratio, axis = 1)\n",
    "test_x = np.append(test_x, np.reshape(test_eq_tp_cd_prob, [14999,1]), axis =1)\n",
    "test_x = np.append(test_x, np.reshape(test_ty_cd_timestamp, [14999,259*6]), axis =1) # 원본 5 \n",
    "test_x = np.append(test_x, test_simul_prob_top_cnt, axis =1)\n",
    "test_x = np.append(test_x, test_timedelta_static, axis =1)\n",
    "test_x = np.append(test_x, test_fpca, axis =1)\n",
    "test_x = np.append(test_x, test_quality_timestamp_features, axis =1)\n",
    "test_x = np.append(test_x, test_quality_negaive_value_cnt, axis =1)\n",
    "test_x = np.append(test_x, test_simultaneous_quality_features.iloc[:,1:].values, axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "executionInfo": {
     "elapsed": 7370,
     "status": "ok",
     "timestamp": 1612437848427,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "92Bf3jwVmRh8"
   },
   "outputs": [],
   "source": [
    "train_err_day_dummy_variable = pd.read_pickle(PATH + \"train_err_day_dummy_variable.pkl\")\n",
    "test_err_day_dummy_variable = pd.read_pickle(PATH + \"test_err_day_dummy_variable.pkl\")\n",
    "train_x = np.append(train_x, train_err_day_dummy_variable[[\"weekday_5_cnt\",\"weekday_6_cnt\",\"active_hour_ratio\"]].values, axis =1)\n",
    "test_x = np.append(test_x, test_err_day_dummy_variable[[\"weekday_5_cnt\",\"weekday_6_cnt\",\"active_hour_ratio\"]].values, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# explainer = shap.TreeExplainer(model) # Tree model Shap Value 확인 객체 지정\n",
    "# shap_values = explainer.shap_values(train_x) # Shap Values 계산\n",
    "# shap_sum = np.abs(shap_values[1]).mean(axis=0)\n",
    "# col_list = [i for i in range(4011)]\n",
    "# importance_df = pd.DataFrame({\"col_idx\":col_list, \"shap_val_mean\":shap_sum})\n",
    "# use_idx = importance_df.query(\"shap_val_mean>0\").sort_values(\"shap_val_mean\", ascending = False).col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "executionInfo": {
     "elapsed": 29519,
     "status": "ok",
     "timestamp": 1612436816264,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "L0fFcBq8Eiat"
   },
   "outputs": [],
   "source": [
    "# 리더보드 재현을 위한 변수 조합 필터링(위의 전체 4011개로 학습한뒤 shap val mean 0인것은 제외하는 과정)\n",
    "importance_df = pd.read_pickle(PATH + \"importance_df.pkl\")\n",
    "use_idx = importance_df.query(\"shap_val_mean != 0 \").col_idx\n",
    "train_x = train_x[:,use_idx]\n",
    "test_x = test_x[:,use_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1050,
     "status": "ok",
     "timestamp": 1612437849484,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "VIOyLZ6zERyn",
    "outputId": "56ed1306-b6e9-440d-ebef-afc823b5b0ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prob = pd.read_csv(RAW_PATH+'train_problem_data.csv')\n",
    "problem = np.zeros(15000)\n",
    "problem[train_prob.user_id.unique()-10000] = 1 \n",
    "problem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlzH7hPiERyn"
   },
   "source": [
    "# 3. Light-gbm 모델 훈련 \n",
    "> 훈련 모델 파일이 미리 저장되어 있으므로 별도 트레인 없이 모델 json파일으로 predict 가능  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1612437851570,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "XDBfnfn9ERyn",
    "outputId": "96d7ad42-4b7b-4260-e643-6554aec9a335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 665)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# 변수 이름 변경\n",
    "train_y = problem\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "executionInfo": {
     "elapsed": 2083,
     "status": "ok",
     "timestamp": 1612437859186,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "aBNWr7_E7nMK"
   },
   "outputs": [],
   "source": [
    "train_x = np.nan_to_num(train_x, 0)\n",
    "test_x = np.nan_to_num(test_x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 638198,
     "status": "ok",
     "timestamp": 1612438495410,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "E_ui-1zwERyo",
    "outputId": "208267b6-9d1b-4d53-d0ff-2155cef4670e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's auc: 0.854929\tvalid_0's pr_auc: 0.78257\n",
      "[100]\tvalid_0's auc: 0.856981\tvalid_0's pr_auc: 0.787295\n",
      "[150]\tvalid_0's auc: 0.859756\tvalid_0's pr_auc: 0.790271\n",
      "[200]\tvalid_0's auc: 0.861934\tvalid_0's pr_auc: 0.802815\n",
      "[250]\tvalid_0's auc: 0.864637\tvalid_0's pr_auc: 0.80516\n",
      "[300]\tvalid_0's auc: 0.865213\tvalid_0's pr_auc: 0.804284\n",
      "==========================================================\n",
      "[50]\tvalid_0's auc: 0.845986\tvalid_0's pr_auc: 0.778081\n",
      "[100]\tvalid_0's auc: 0.848846\tvalid_0's pr_auc: 0.785118\n",
      "[150]\tvalid_0's auc: 0.849107\tvalid_0's pr_auc: 0.782187\n",
      "[200]\tvalid_0's auc: 0.849586\tvalid_0's pr_auc: 0.784552\n",
      "[250]\tvalid_0's auc: 0.851715\tvalid_0's pr_auc: 0.788918\n",
      "[300]\tvalid_0's auc: 0.854739\tvalid_0's pr_auc: 0.792077\n",
      "==========================================================\n",
      "[50]\tvalid_0's auc: 0.874084\tvalid_0's pr_auc: 0.82044\n",
      "[100]\tvalid_0's auc: 0.876155\tvalid_0's pr_auc: 0.82223\n",
      "[150]\tvalid_0's auc: 0.874498\tvalid_0's pr_auc: 0.82225\n",
      "[200]\tvalid_0's auc: 0.876946\tvalid_0's pr_auc: 0.822465\n",
      "[250]\tvalid_0's auc: 0.877924\tvalid_0's pr_auc: 0.82387\n",
      "[300]\tvalid_0's auc: 0.877187\tvalid_0's pr_auc: 0.820627\n",
      "==========================================================\n",
      "[50]\tvalid_0's auc: 0.835515\tvalid_0's pr_auc: 0.762887\n",
      "[100]\tvalid_0's auc: 0.836406\tvalid_0's pr_auc: 0.76207\n",
      "[150]\tvalid_0's auc: 0.839141\tvalid_0's pr_auc: 0.76744\n",
      "[200]\tvalid_0's auc: 0.841504\tvalid_0's pr_auc: 0.774947\n",
      "[250]\tvalid_0's auc: 0.841855\tvalid_0's pr_auc: 0.774834\n",
      "[300]\tvalid_0's auc: 0.842659\tvalid_0's pr_auc: 0.776294\n",
      "==========================================================\n",
      "[50]\tvalid_0's auc: 0.826624\tvalid_0's pr_auc: 0.742478\n",
      "[100]\tvalid_0's auc: 0.830447\tvalid_0's pr_auc: 0.754138\n",
      "[150]\tvalid_0's auc: 0.83427\tvalid_0's pr_auc: 0.757666\n",
      "[200]\tvalid_0's auc: 0.835741\tvalid_0's pr_auc: 0.757586\n",
      "[250]\tvalid_0's auc: 0.837426\tvalid_0's pr_auc: 0.75884\n",
      "[300]\tvalid_0's auc: 0.837658\tvalid_0's pr_auc: 0.760775\n",
      "==========================================================\n",
      "[50]\tvalid_0's auc: 0.852984\tvalid_0's pr_auc: 0.789739\n",
      "[100]\tvalid_0's auc: 0.858943\tvalid_0's pr_auc: 0.796894\n",
      "[150]\tvalid_0's auc: 0.857898\tvalid_0's pr_auc: 0.79468\n",
      "[200]\tvalid_0's auc: 0.857745\tvalid_0's pr_auc: 0.794646\n",
      "[250]\tvalid_0's auc: 0.858094\tvalid_0's pr_auc: 0.796233\n",
      "[300]\tvalid_0's auc: 0.859959\tvalid_0's pr_auc: 0.798621\n",
      "==========================================================\n",
      "[50]\tvalid_0's auc: 0.834422\tvalid_0's pr_auc: 0.749036\n",
      "[100]\tvalid_0's auc: 0.839662\tvalid_0's pr_auc: 0.759094\n",
      "[150]\tvalid_0's auc: 0.84174\tvalid_0's pr_auc: 0.760733\n",
      "[200]\tvalid_0's auc: 0.84298\tvalid_0's pr_auc: 0.762111\n",
      "[250]\tvalid_0's auc: 0.845373\tvalid_0's pr_auc: 0.764389\n",
      "[300]\tvalid_0's auc: 0.84673\tvalid_0's pr_auc: 0.765194\n",
      "==========================================================\n",
      "[50]\tvalid_0's auc: 0.836664\tvalid_0's pr_auc: 0.770328\n",
      "[100]\tvalid_0's auc: 0.84324\tvalid_0's pr_auc: 0.778772\n",
      "[150]\tvalid_0's auc: 0.84577\tvalid_0's pr_auc: 0.780467\n",
      "[200]\tvalid_0's auc: 0.850323\tvalid_0's pr_auc: 0.785459\n",
      "[250]\tvalid_0's auc: 0.85088\tvalid_0's pr_auc: 0.78707\n",
      "[300]\tvalid_0's auc: 0.849299\tvalid_0's pr_auc: 0.783788\n",
      "==========================================================\n",
      "[50]\tvalid_0's auc: 0.849682\tvalid_0's pr_auc: 0.77277\n",
      "[100]\tvalid_0's auc: 0.853036\tvalid_0's pr_auc: 0.775001\n",
      "[150]\tvalid_0's auc: 0.853171\tvalid_0's pr_auc: 0.778742\n",
      "[200]\tvalid_0's auc: 0.853064\tvalid_0's pr_auc: 0.777797\n",
      "[250]\tvalid_0's auc: 0.855762\tvalid_0's pr_auc: 0.781538\n",
      "[300]\tvalid_0's auc: 0.855327\tvalid_0's pr_auc: 0.781338\n",
      "==========================================================\n",
      "[50]\tvalid_0's auc: 0.829396\tvalid_0's pr_auc: 0.743499\n",
      "[100]\tvalid_0's auc: 0.831801\tvalid_0's pr_auc: 0.748046\n",
      "[150]\tvalid_0's auc: 0.834414\tvalid_0's pr_auc: 0.751499\n",
      "[200]\tvalid_0's auc: 0.83569\tvalid_0's pr_auc: 0.756933\n",
      "[250]\tvalid_0's auc: 0.836869\tvalid_0's pr_auc: 0.759297\n",
      "[300]\tvalid_0's auc: 0.837664\tvalid_0's pr_auc: 0.759014\n",
      "==========================================================\n",
      "4 0.8526434660456097 0.011917512623145879\n",
      "[0.8652125179071287, 0.854739293395749, 0.8771870029538742, 0.8426585887384177, 0.8376581127500506, 0.8599594826242792, 0.8467298704342627, 0.8492989643702475, 0.8553265014058807, 0.8376643258762058]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_auc = []\n",
    "final_auc_dic = {}\n",
    "for random_state in [4]:\n",
    "  # Train\n",
    "  #-------------------------------------------------------------------------------------\n",
    "  # validation auc score를 확인하기 위해 정의\n",
    "  def f_pr_auc(probas_pred, y_true):\n",
    "      labels=y_true.get_label()\n",
    "      p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "      score=auc(r,p) \n",
    "      return \"pr_auc\", score, True\n",
    "  #-------------------------------------------------------------------------------------\n",
    "  models     = []\n",
    "  recalls    = []\n",
    "  precisions = []\n",
    "  auc_scores   = []\n",
    "  threshold = 0.5\n",
    "  # 파라미터 설정\n",
    "  params =      {\n",
    "                  'boosting_type' : 'dart',\n",
    "                  'objective'     : 'binary',\n",
    "                  'metric'        : 'auc',\n",
    "                  }\n",
    "  #-------------------------------------------------------------------------------------\n",
    "  # 10-fold cross validation\n",
    "  k_fold = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "  from collections import Counter\n",
    "  for train_idx, val_idx in k_fold.split(train_x,train_y):\n",
    "      \n",
    "      # split train, validation set\n",
    "      X = train_x[train_idx]\n",
    "      y = train_y[train_idx]\n",
    "      valid_x = train_x[val_idx]\n",
    "      valid_y = train_y[val_idx]\n",
    "      d_train= lgb.Dataset(X, y)\n",
    "      d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "      \n",
    "      #run traning\n",
    "      model = lgb.train(\n",
    "                          \n",
    "                          params,\n",
    "                          train_set       = d_train,\n",
    "                          num_boost_round = 300, \n",
    "                          valid_sets      = d_val,\n",
    "                          feval           = f_pr_auc,\n",
    "                          verbose_eval    = 50, \n",
    "#                           early_stopping_rounds = 100,\n",
    "                        )\n",
    "      \n",
    "      # cal valid prediction\n",
    "      valid_prob = model.predict(valid_x)\n",
    "      valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "      \n",
    "      # cal scores\n",
    "      recall    = recall_score(valid_y, valid_pred)\n",
    "      precision = precision_score( valid_y, valid_pred)\n",
    "      auc_score = roc_auc_score(valid_y, valid_prob)\n",
    "\n",
    "      # append scores\n",
    "      models.append(model)\n",
    "      recalls.append(recall)\n",
    "      precisions.append(precision)\n",
    "      auc_scores.append(auc_score)\n",
    "  \n",
    "      print('==========================================================')\n",
    "  print(random_state, np.mean(auc_scores),np.std(auc_scores) )\n",
    "  final_auc_dic[random_state] = np.mean(auc_scores) # 랜덤 state별 k-fold 별 auc score \n",
    "  final_auc.append(np.mean(auc_scores)) # 랜덤 state별 auc score \n",
    "  print(auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ADRoKkwERyo"
   },
   "source": [
    "# 4. 교차검증 점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 트레인 모델을 불러와서 사용 가능\n",
    "import joblib\n",
    "# joblib.dump( model, PATH + 'lgb.pkl')\n",
    "# model = joblib.load( PATH + 'lgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "executionInfo": {
     "elapsed": 3704,
     "status": "ok",
     "timestamp": 1612367161840,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "GBHZszF0ERyp"
   },
   "outputs": [],
   "source": [
    "# 예측\n",
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(test_x)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1612367168371,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "Rs2ztJ8lERyq"
   },
   "outputs": [],
   "source": [
    "sample_submssion = pd.read_csv(RAW_PATH+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1612367169898,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "OA1cE3l2ERyq"
   },
   "outputs": [],
   "source": [
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1612367171064,
     "user": {
      "displayName": "yang jo",
      "photoUrl": "",
      "userId": "01079575632044760993"
     },
     "user_tz": -540
    },
    "id": "9xXeaNsjERyq",
    "outputId": "869f2aa8-bfef-4b73-b854-79389980efe5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.928659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.499147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.614533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.775865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.956908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.366660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.289906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.754851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.878986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.429592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.928659\n",
       "1        30001  0.499147\n",
       "2        30002  0.614533\n",
       "3        30003  0.775865\n",
       "4        30004  0.956908\n",
       "...        ...       ...\n",
       "14994    44994  0.366660\n",
       "14995    44995  0.289906\n",
       "14996    44996  0.754851\n",
       "14997    44997  0.878986\n",
       "14998    44998  0.429592\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submssion.to_csv(\"test.csv\", index = False)\n",
    "# sample_submssion.to_csv(\"lb_score_0.84786.csv\", index = False)\n",
    "sample_submssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
